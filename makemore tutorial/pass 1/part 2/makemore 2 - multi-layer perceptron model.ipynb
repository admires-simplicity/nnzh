{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "552aa5a8-1c05-4ab5-9653-656cb4c89428",
   "metadata": {},
   "outputs": [],
   "source": [
    "# name generation model\n",
    "# based on this paper: https://www.jmlr.org/papers/volume3/bengio03a/bengio03a.pdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f694b08d-9534-4b04-ab57-5ad37b89c24c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn.functional as F\n",
    "import matplotlib.pyplot as plt # for making figures\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e918d40a-6dd5-4d61-a6f5-ea7d05a999df",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['emma', 'olivia', 'ava', 'isabella', 'sophia', 'charlotte', 'mia', 'amelia']"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# read  in all the words\n",
    "words = open('names.txt', 'r').read().splitlines()\n",
    "words[:8]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "fe49c448-a633-4076-9353-5d244ea8a0f6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "32033"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "97b384bf-c57e-4dce-ae24-6c9f51f7b0f4",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{1: 'a', 2: 'b', 3: 'c', 4: 'd', 5: 'e', 6: 'f', 7: 'g', 8: 'h', 9: 'i', 10: 'j', 11: 'k', 12: 'l', 13: 'm', 14: 'n', 15: 'o', 16: 'p', 17: 'q', 18: 'r', 19: 's', 20: 't', 21: 'u', 22: 'v', 23: 'w', 24: 'x', 25: 'y', 26: 'z', 0: '.'}\n"
     ]
    }
   ],
   "source": [
    "# build the vocabulary of characters and mappings to/from integers\n",
    "chars = sorted(list(set(''.join(words))))\n",
    "stoi = {s:i+1 for i,s in enumerate(chars)}\n",
    "stoi['.'] = 0\n",
    "itos = {i:s for s,i in stoi.items()}\n",
    "print(itos)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5004cf44-226d-4c23-a423-280db68ee8cd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "emma\n",
      "... ---> e\n",
      "..e ---> m\n",
      ".em ---> m\n",
      "emm ---> a\n",
      "mma ---> .\n",
      "olivia\n",
      "... ---> o\n",
      "..o ---> l\n",
      ".ol ---> i\n",
      "oli ---> v\n",
      "liv ---> i\n",
      "ivi ---> a\n",
      "via ---> .\n",
      "ava\n",
      "... ---> a\n",
      "..a ---> v\n",
      ".av ---> a\n",
      "ava ---> .\n",
      "isabella\n",
      "... ---> i\n",
      "..i ---> s\n",
      ".is ---> a\n",
      "isa ---> b\n",
      "sab ---> e\n",
      "abe ---> l\n",
      "bel ---> l\n",
      "ell ---> a\n",
      "lla ---> .\n",
      "sophia\n",
      "... ---> s\n",
      "..s ---> o\n",
      ".so ---> p\n",
      "sop ---> h\n",
      "oph ---> i\n",
      "phi ---> a\n",
      "hia ---> .\n"
     ]
    }
   ],
   "source": [
    "# build the dataset\n",
    "\n",
    "block_size = 3 # context length: how many characters do we take to predict the next one?\n",
    "               # original paper uses a cotext of 3 words\n",
    "X, Y = [], []\n",
    "for w in words[:5]:\n",
    "    print(w)\n",
    "    context = [0] * block_size\n",
    "    for ch in w + '.':\n",
    "        ix = stoi[ch]\n",
    "        X.append(context)\n",
    "        Y.append(ix)\n",
    "        print(''.join(itos[i] for i in context), '--->', itos[ix])\n",
    "        context = context[1:] + [ix] # crop first character and append, rolling window\n",
    "\n",
    "X = torch.tensor(X)\n",
    "Y = torch.tensor(Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "adf87248-14c8-4fc2-ac4e-d46d3c345409",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([32, 3]), torch.int64, torch.Size([32]), torch.int64)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape, X.dtype, Y.shape, Y.dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a9c3003e-1b6c-40db-a50c-438b6bfd9481",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0,  0,  0],\n",
       "        [ 0,  0,  5],\n",
       "        [ 0,  5, 13],\n",
       "        [ 5, 13, 13],\n",
       "        [13, 13,  1],\n",
       "        [ 0,  0,  0],\n",
       "        [ 0,  0, 15],\n",
       "        [ 0, 15, 12],\n",
       "        [15, 12,  9],\n",
       "        [12,  9, 22],\n",
       "        [ 9, 22,  9],\n",
       "        [22,  9,  1],\n",
       "        [ 0,  0,  0],\n",
       "        [ 0,  0,  1],\n",
       "        [ 0,  1, 22],\n",
       "        [ 1, 22,  1],\n",
       "        [ 0,  0,  0],\n",
       "        [ 0,  0,  9],\n",
       "        [ 0,  9, 19],\n",
       "        [ 9, 19,  1],\n",
       "        [19,  1,  2],\n",
       "        [ 1,  2,  5],\n",
       "        [ 2,  5, 12],\n",
       "        [ 5, 12, 12],\n",
       "        [12, 12,  1],\n",
       "        [ 0,  0,  0],\n",
       "        [ 0,  0, 19],\n",
       "        [ 0, 19, 15],\n",
       "        [19, 15, 16],\n",
       "        [15, 16,  8],\n",
       "        [16,  8,  9],\n",
       "        [ 8,  9,  1]])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b9904fee-f22b-4395-8502-074bb204d1d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# embed input in lower dimensional space\n",
    "# original paper embeds 17,000 words in 30 dimensional space\n",
    "# we have 27 possible input characters. let's try a 2 dimensional space.\n",
    "C = torch.randn((27, 2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "aab79473-5ba9-49f4-885d-dce3acfae1ff",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.6529, -0.5013],\n",
       "        [ 0.7260, -1.0445],\n",
       "        [ 1.2410,  0.3941]])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "C[torch.tensor([5, 6, 7])] # using list or tensor as index instead of number gives us a tensor of the respective values in C"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "6a294cf2-6958-42ed-b7ec-98fb78f11ed9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[ 1.0715,  0.6954],\n",
       "         [ 1.0715,  0.6954],\n",
       "         [ 1.0715,  0.6954]],\n",
       "\n",
       "        [[ 1.0715,  0.6954],\n",
       "         [ 1.0715,  0.6954],\n",
       "         [ 0.6529, -0.5013]],\n",
       "\n",
       "        [[ 1.0715,  0.6954],\n",
       "         [ 0.6529, -0.5013],\n",
       "         [-1.1747, -0.1716]],\n",
       "\n",
       "        [[ 0.6529, -0.5013],\n",
       "         [-1.1747, -0.1716],\n",
       "         [-1.1747, -0.1716]],\n",
       "\n",
       "        [[-1.1747, -0.1716],\n",
       "         [-1.1747, -0.1716],\n",
       "         [ 0.3782,  0.7977]],\n",
       "\n",
       "        [[ 1.0715,  0.6954],\n",
       "         [ 1.0715,  0.6954],\n",
       "         [ 1.0715,  0.6954]],\n",
       "\n",
       "        [[ 1.0715,  0.6954],\n",
       "         [ 1.0715,  0.6954],\n",
       "         [ 0.2579,  2.1787]],\n",
       "\n",
       "        [[ 1.0715,  0.6954],\n",
       "         [ 0.2579,  2.1787],\n",
       "         [ 2.6669,  0.9808]],\n",
       "\n",
       "        [[ 0.2579,  2.1787],\n",
       "         [ 2.6669,  0.9808],\n",
       "         [ 0.9003, -0.4425]],\n",
       "\n",
       "        [[ 2.6669,  0.9808],\n",
       "         [ 0.9003, -0.4425],\n",
       "         [ 0.8257,  0.4894]],\n",
       "\n",
       "        [[ 0.9003, -0.4425],\n",
       "         [ 0.8257,  0.4894],\n",
       "         [ 0.9003, -0.4425]],\n",
       "\n",
       "        [[ 0.8257,  0.4894],\n",
       "         [ 0.9003, -0.4425],\n",
       "         [ 0.3782,  0.7977]],\n",
       "\n",
       "        [[ 1.0715,  0.6954],\n",
       "         [ 1.0715,  0.6954],\n",
       "         [ 1.0715,  0.6954]],\n",
       "\n",
       "        [[ 1.0715,  0.6954],\n",
       "         [ 1.0715,  0.6954],\n",
       "         [ 0.3782,  0.7977]],\n",
       "\n",
       "        [[ 1.0715,  0.6954],\n",
       "         [ 0.3782,  0.7977],\n",
       "         [ 0.8257,  0.4894]],\n",
       "\n",
       "        [[ 0.3782,  0.7977],\n",
       "         [ 0.8257,  0.4894],\n",
       "         [ 0.3782,  0.7977]],\n",
       "\n",
       "        [[ 1.0715,  0.6954],\n",
       "         [ 1.0715,  0.6954],\n",
       "         [ 1.0715,  0.6954]],\n",
       "\n",
       "        [[ 1.0715,  0.6954],\n",
       "         [ 1.0715,  0.6954],\n",
       "         [ 0.9003, -0.4425]],\n",
       "\n",
       "        [[ 1.0715,  0.6954],\n",
       "         [ 0.9003, -0.4425],\n",
       "         [-0.3051,  0.4799]],\n",
       "\n",
       "        [[ 0.9003, -0.4425],\n",
       "         [-0.3051,  0.4799],\n",
       "         [ 0.3782,  0.7977]],\n",
       "\n",
       "        [[-0.3051,  0.4799],\n",
       "         [ 0.3782,  0.7977],\n",
       "         [ 0.6223, -1.8771]],\n",
       "\n",
       "        [[ 0.3782,  0.7977],\n",
       "         [ 0.6223, -1.8771],\n",
       "         [ 0.6529, -0.5013]],\n",
       "\n",
       "        [[ 0.6223, -1.8771],\n",
       "         [ 0.6529, -0.5013],\n",
       "         [ 2.6669,  0.9808]],\n",
       "\n",
       "        [[ 0.6529, -0.5013],\n",
       "         [ 2.6669,  0.9808],\n",
       "         [ 2.6669,  0.9808]],\n",
       "\n",
       "        [[ 2.6669,  0.9808],\n",
       "         [ 2.6669,  0.9808],\n",
       "         [ 0.3782,  0.7977]],\n",
       "\n",
       "        [[ 1.0715,  0.6954],\n",
       "         [ 1.0715,  0.6954],\n",
       "         [ 1.0715,  0.6954]],\n",
       "\n",
       "        [[ 1.0715,  0.6954],\n",
       "         [ 1.0715,  0.6954],\n",
       "         [-0.3051,  0.4799]],\n",
       "\n",
       "        [[ 1.0715,  0.6954],\n",
       "         [-0.3051,  0.4799],\n",
       "         [ 0.2579,  2.1787]],\n",
       "\n",
       "        [[-0.3051,  0.4799],\n",
       "         [ 0.2579,  2.1787],\n",
       "         [ 0.2501, -1.0460]],\n",
       "\n",
       "        [[ 0.2579,  2.1787],\n",
       "         [ 0.2501, -1.0460],\n",
       "         [ 1.8043, -0.8059]],\n",
       "\n",
       "        [[ 0.2501, -1.0460],\n",
       "         [ 1.8043, -0.8059],\n",
       "         [ 0.9003, -0.4425]],\n",
       "\n",
       "        [[ 1.8043, -0.8059],\n",
       "         [ 0.9003, -0.4425],\n",
       "         [ 0.3782,  0.7977]]])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "emb = C[X] # we can also index with multidimensional integers\n",
    "emb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "2fbd16b4-0eca-492f-844c-1184a67e2b92",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([32, 3, 2])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "emb.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "76af0273-b13a-4991-ac7f-4f86f62fa652",
   "metadata": {},
   "outputs": [],
   "source": [
    "# hidden layer\n",
    "W1 = torch.randn((6, 100)) # weights\n",
    "# 6 x 100 because:\n",
    "# (number of inputs == 6 == embedding dimensions (2) x n-embeddings per input (3))\n",
    "#   x \n",
    "# (number of neurons in this layer == some arbitrary amount of neurons (100))\n",
    "b1 = torch.randn(100) # biases"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "ad715e39-e0bb-4802-8e11-e8bd74fcea65",
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "mat1 and mat2 shapes cannot be multiplied (96x2 and 6x100)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[15], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43memb\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m@\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mW1\u001b[49m \u001b[38;5;241m+\u001b[39m b1 \u001b[38;5;66;03m# what we want to do\u001b[39;00m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: mat1 and mat2 shapes cannot be multiplied (96x2 and 6x100)"
     ]
    }
   ],
   "source": [
    "emb @ W1 + b1 # what we want to do"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9bf27005-cc6d-4d0b-8341-cbb6800957a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# but it doesn't work because each element in emb has size (3x2) instead of size 6.\n",
    "# we need to smush these together somehow.\n",
    "# there are multiple ways to acheive this depending on exact requirements\n",
    "# we'll use torch.cat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4244c02-0362-4a0b-87a2-fe6741ede611",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.cat([emb[:, 0, :], emb[:, 1, :], emb[:, 2, :]], 1)\n",
    "# this will do it, but it's ugly because it's hard-coded.\n",
    "# what if we wanted to change the dimensions of emb from e.g. (_, 3, _) to (_, M, _) ?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8297fa8-0e83-46db-b304-72030fe44e4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ans: use torch.unbind\n",
    "#torch.unbind(emb, 1) # == [emb[:, 0, :], emb[:, 1, :], emb[:, 2, :]]\n",
    "torch.cat(torch.unbind(emb, 1), 1)\n",
    "# unfortunately, this is SUPA INEFFICIENT, because torch.cat will copy everything..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "774e0659-255f-4c07-a471-0c1166417e46",
   "metadata": {},
   "outputs": [],
   "source": [
    "# even BETTER + EFFICIENT ans: use tensor.view!\n",
    "# changes how tensor is INDEXED instead of STORED. efficient!\n",
    "# changes storage offset, strides, and shapes\n",
    "emb.view(32, 6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e162c283-a869-4ea7-9f80-c76bae5755c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "h = torch.tanh(emb.view(emb.shape[0], 6) @ W1 + b1)\n",
    "# activations of inputs emb (h for \"hidden states\")\n",
    "# could do emb.view(-1, 6) and pytorch would figure out what the first dimension needs to be in order to make the size work\n",
    "h.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ddb4a76e-31d6-4bda-baed-82542573ba08",
   "metadata": {},
   "outputs": [],
   "source": [
    "h"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fefe14e3-9712-433c-990c-44dbc901d8f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# let's make sure the expression \"emb.view(emb.shape[0], 6) @ W1 + b1\"\n",
    "# is broadcasting correctly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c134812-2567-4e1d-a324-ac789d7b2ee9",
   "metadata": {},
   "outputs": [],
   "source": [
    "(emb.view(emb.shape[0], 6) @ W1).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d2e6050-2795-418d-a55c-5fdd19e33c5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "b1.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76ff1e7b-ca4e-428d-b876-559dc8e240b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# align on right, make missing dimensions size 1, then copy all dimensions of size 1\n",
    "# 32 100    32 100    32 100\n",
    "#    100 ->  1 100 -> 32 100\n",
    "# so it's correct (note: in case this looks wrong because we know \n",
    "#                        matrix multiplication needs (N, M) x (M, O) dimensions,\n",
    "#                        remember we're not doing a multiplication on these\n",
    "#                        two values, we're doing an addition, so we actually\n",
    "#                        do want identical sizes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8512fe1c-42bb-4274-8962-83ca09ec6e90",
   "metadata": {},
   "outputs": [],
   "source": [
    "# final layer\n",
    "W2 = torch.randn((100, 27)) # input size -> 27 characters\n",
    "b2 = torch.randn(27)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5428ae0-f5ed-48c5-8b2a-cd5d1805ced4",
   "metadata": {},
   "outputs": [],
   "source": [
    "logits = h @ W2 + b2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd1f5f4a-3f12-4fa0-9b08-c6f3c0b298e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "logits.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a158efa-6a0f-4ba6-a4be-5ffee43f5be8",
   "metadata": {},
   "outputs": [],
   "source": [
    "counts = logits.exp()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c61aff17-6da2-4c86-8e05-c6129bb05068",
   "metadata": {},
   "outputs": [],
   "source": [
    "prob = counts / counts.sum(1, keepdims=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d79288c9-6da3-4e77-ad83-f60f716986e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "prob.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70f85842-098b-47a0-8fb5-144857217217",
   "metadata": {},
   "outputs": [],
   "source": [
    "prob.sum(1, keepdims=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65748a42-446c-4dec-af52-5fab6b9469eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "prob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d75948ba-eba6-4ad8-bf6f-4a06dd8ecb96",
   "metadata": {},
   "outputs": [],
   "source": [
    "# let's look at how likely the neural net thought the actual outputs were\n",
    "prob[torch.arange(32), Y]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88929f87-05db-4e2d-b244-07bdc9f5b2d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# that's pretty bad, but it's ok because we haven't trained it at all yet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4385fb57-2617-4559-b50b-8e528fdeafa6",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.arange(32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3de0adc1-d02f-40aa-a312-d46df4338fe4",
   "metadata": {},
   "outputs": [],
   "source": [
    "Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22637fa3-d652-4305-924b-f0f4450a9a4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "loss = -prob[torch.arange(32), Y].log().mean()\n",
    "loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc5b4b09-f921-46af-b80d-71b1c1b36f5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ----------------------------------------------------------------\n",
    "# TIDIED UP! (more respectable)\n",
    "# ----------------------------------------------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3103df59-90de-4c88-b710-8965e57948a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "X.shape, Y.shape # dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "990babc3-6a5b-4d0f-9f08-ed6e55999a97",
   "metadata": {},
   "outputs": [],
   "source": [
    "g = torch.Generator().manual_seed(2 ** 31 - 1) # for reproducibility\n",
    "C = torch.randn((27, 2), generator=g)\n",
    "# hidden layer\n",
    "W1 = torch.randn((6, 100), generator=g) # weights\n",
    "b1 = torch.randn(100, generator=g) # biases\n",
    "# output layer (right?)\n",
    "W2 = torch.randn((100, 27), generator=g)\n",
    "b2 = torch.randn(27, generator=g)\n",
    "parameters = [C, W1, b1, W2, b2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca7feef2-2a80-48d7-bbaf-06466a058cf1",
   "metadata": {},
   "outputs": [],
   "source": [
    "sum(p.nelement() for p in parameters) # number of parameters in total"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32930ab5-b564-4554-81a5-7ebbbb8185bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "emb = C[X] # [32, 3, 2]\n",
    "h = torch.tanh(emb.view(-1, 6) @ W1 + b1) # (32, 100)\n",
    "logits = h @ W2 + b2 # (32, 27)\n",
    "counts = logits.exp()\n",
    "prob = counts / counts.sum(1, keepdims=True)\n",
    "loss = -prob[torch.arange(32), Y].log().mean()\n",
    "loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "299a18f9-5db5-45d9-a684-4ba02af2246e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ----------------------------------------------------------------\n",
    "# TIDIED UP, 2! (even MORE respectable)\n",
    "# ----------------------------------------------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3ae2ff8-bb6a-4c55-ab20-09ea56320db9",
   "metadata": {},
   "outputs": [],
   "source": [
    "X.shape, Y.shape # dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d12bf65-f375-4f22-b939-b86765d43488",
   "metadata": {},
   "outputs": [],
   "source": [
    "g = torch.Generator().manual_seed(2 ** 31 - 1) # for reproducibility\n",
    "C = torch.randn((27, 2), generator=g)\n",
    "# hidden layer\n",
    "W1 = torch.randn((6, 100), generator=g) # weights\n",
    "b1 = torch.randn(100, generator=g) # biases\n",
    "# output layer (right?)\n",
    "W2 = torch.randn((100, 27), generator=g)\n",
    "b2 = torch.randn(27, generator=g)\n",
    "parameters = [C, W1, b1, W2, b2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a22a244-1810-413d-a29b-a4a357b38141",
   "metadata": {},
   "outputs": [],
   "source": [
    "sum(p.nelement() for p in parameters) # number of parameters in total"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "159eb64a-8aab-4dbd-b6a9-848de81fb0e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "emb = C[X] # [32, 3, 2]\n",
    "h = torch.tanh(emb.view(-1, 6) @ W1 + b1) # (32, 100)\n",
    "logits = h @ W2 + b2 # (32, 27)\n",
    "loss = F.cross_entropy(logits, Y)\n",
    "loss\n",
    "# andrej explains a bunch of reasons to use F.cross_entropy instead of making your\n",
    "# own loss function\n",
    "# 1. efficiency -- pytorch can skip creating intermediate tensors which waste memory\n",
    "#    and can group operations together or something for more computational\n",
    "#    efficiency ??\n",
    "# 2. backward pass is more efficient because F.cross_entropy knows how to do\n",
    "#    backpropogation better or something ??\n",
    "# 3. better numerical behaviour -- you skip the bug where calling logits.exp() ends\n",
    "#    up giving you floating point infinity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "798aec57-8125-47bd-92dd-8c6c25c6ef5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ----------------------------------------------------------------\n",
    "# ITERATION 3, MAKE IT ITERATE! (now we're LEARNING with MACHINES)\n",
    "# ----------------------------------------------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f6c396c-61fc-43c9-a470-d8a93cd9499e",
   "metadata": {},
   "outputs": [],
   "source": [
    "X.shape, Y.shape # dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2941b891-68f7-4e24-a4ed-79110a4d181b",
   "metadata": {},
   "outputs": [],
   "source": [
    "g = torch.Generator().manual_seed(2 ** 31 - 1) # for reproducibility\n",
    "C = torch.randn((27, 2), generator=g)\n",
    "# hidden layer\n",
    "W1 = torch.randn((6, 100), generator=g) # weights\n",
    "b1 = torch.randn(100, generator=g) # biases\n",
    "# output layer (right?)\n",
    "W2 = torch.randn((100, 27), generator=g)\n",
    "b2 = torch.randn(27, generator=g)\n",
    "parameters = [C, W1, b1, W2, b2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b48f3f67-0b2e-4d31-8160-7033e4b513ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "sum(p.nelement() for p in parameters) # number of parameters in total"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "343ebbfb-369c-47ea-9f1e-ebcccf91c90e",
   "metadata": {},
   "outputs": [],
   "source": [
    "for p in parameters:\n",
    "    p.requires_grad = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8dbb9b13-391f-4389-bc02-5dd9507b527c",
   "metadata": {},
   "outputs": [],
   "source": [
    "for _ in range(10):\n",
    "    # forward pass\n",
    "    emb = C[X] # [32, 3, 2]\n",
    "    h = torch.tanh(emb.view(-1, 6) @ W1 + b1) # (32, 100)\n",
    "    logits = h @ W2 + b2 # (32, 27)\n",
    "    loss = F.cross_entropy(logits, Y)\n",
    "    print(loss.item())\n",
    "    # backward pass\n",
    "    for p in parameters:\n",
    "        p.grad = None\n",
    "    loss.backward()\n",
    "    # update\n",
    "    for p in parameters:\n",
    "        p.data += -0.1 * p.grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "148bd446-8dc6-4696-ab55-7cb9ffa70223",
   "metadata": {},
   "outputs": [],
   "source": [
    "# here are the actual highest likelihood predictions\n",
    "logits.max(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f14a5deb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ----------------------------------------------------------------\n",
    "# iteration 4 -- FULL DATASET TIME!\n",
    "# ----------------------------------------------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ed724eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "block_size = 3 # context length: how many characters do we take to predict the next one?\n",
    "               # original paper uses a cotext of 3 words\n",
    "X, Y = [], []\n",
    "for w in words:\n",
    "    #print(w)\n",
    "    context = [0] * block_size\n",
    "    for ch in w + '.':\n",
    "        ix = stoi[ch]\n",
    "        X.append(context)\n",
    "        Y.append(ix)\n",
    "        #print(''.join(itos[i] for i in context), '--->', itos[ix])\n",
    "        context = context[1:] + [ix] # crop first character and append, rolling window\n",
    "\n",
    "X = torch.tensor(X)\n",
    "Y = torch.tensor(Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "851abb89",
   "metadata": {},
   "outputs": [],
   "source": [
    "X.shape, X.dtype, Y.shape, Y.dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e038938",
   "metadata": {},
   "outputs": [],
   "source": [
    "g = torch.Generator().manual_seed(2 ** 31 - 1) # for reproducibility\n",
    "C = torch.randn((27, 2), generator=g)\n",
    "# hidden layer\n",
    "W1 = torch.randn((6, 100), generator=g) # weights\n",
    "b1 = torch.randn(100, generator=g) # biases\n",
    "# output layer (right?)\n",
    "W2 = torch.randn((100, 27), generator=g)\n",
    "b2 = torch.randn(27, generator=g)\n",
    "parameters = [C, W1, b1, W2, b2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c79e410d",
   "metadata": {},
   "outputs": [],
   "source": [
    "sum(p.nelement() for p in parameters) # number of parameters in total"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73b845f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "for p in parameters:\n",
    "    p.requires_grad = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5cdb6435",
   "metadata": {},
   "outputs": [],
   "source": [
    "for _ in range(1000):   \n",
    "    # forward pass\n",
    "    #emb = C[X] # [32, 3, 2]\n",
    "    # this works but is slow. let's use random subsets of the data to train instead in order to have faster\n",
    "    # training cycles\n",
    "    \n",
    "    ix = torch.randint(0, X.shape[0], (32,))\n",
    "    emb = C[X[ix]]\n",
    "    \n",
    "    h = torch.tanh(emb.view(-1, 6) @ W1 + b1) # (32, 100)\n",
    "    logits = h @ W2 + b2 # (32, 27)\n",
    "    loss = F.cross_entropy(logits, Y[ix]) # ALSO INDEXING INTO BATCH HERE\n",
    "    print(loss.item())\n",
    "    # backward pass\n",
    "    for p in parameters:\n",
    "        p.grad = None\n",
    "    loss.backward()\n",
    "    # update\n",
    "    for p in parameters:\n",
    "        p.data += -0.1 * p.grad\n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e589f785",
   "metadata": {},
   "outputs": [],
   "source": [
    "# example mini batch\n",
    "torch.randint(0, X.shape[0], (32,))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ff20e2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# let's check the loss on all the examples\n",
    "emb = C[X]    \n",
    "h = torch.tanh(emb.view(-1, 6) @ W1 + b1) # (32, 100)\n",
    "logits = h @ W2 + b2 # (32, 27)\n",
    "loss = F.cross_entropy(logits, Y)\n",
    "loss\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e134fcc1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ----------------------------------------------------------------\n",
    "# iteration 5\n",
    "# ----------------------------------------------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba1ebe45",
   "metadata": {},
   "outputs": [],
   "source": [
    "# now let's learn how to LEARN a good learning rate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9353f1f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "X.shape, X.dtype, Y.shape, Y.dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ad8973c",
   "metadata": {},
   "outputs": [],
   "source": [
    "g = torch.Generator().manual_seed(2 ** 31 - 1) # for reproducibility\n",
    "C = torch.randn((27, 2), generator=g)\n",
    "# hidden layer\n",
    "W1 = torch.randn((6, 100), generator=g) # weights\n",
    "b1 = torch.randn(100, generator=g) # biases\n",
    "# output layer (right?)\n",
    "W2 = torch.randn((100, 27), generator=g)\n",
    "b2 = torch.randn(27, generator=g)\n",
    "parameters = [C, W1, b1, W2, b2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5088c45c",
   "metadata": {},
   "outputs": [],
   "source": [
    "sum(p.nelement() for p in parameters) # number of parameters in total"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a03bb6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "for p in parameters:\n",
    "    p.requires_grad = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4cc4d807",
   "metadata": {},
   "outputs": [],
   "source": [
    "lre = torch.linspace(-3, 0, 1000) # lre -- learning rate exponents\n",
    "lrs = 10**lre\n",
    "lrs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f966d2a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "lri = []\n",
    "lossi = []\n",
    "\n",
    "for i in range(1000):   \n",
    "\n",
    "    #minibatch\n",
    "    ix = torch.randint(0, X.shape[0], (32,))\n",
    "\n",
    "    # forward pass    \n",
    "    emb = C[X[ix]]\n",
    "    \n",
    "    h = torch.tanh(emb.view(-1, 6) @ W1 + b1) # (32, 100)\n",
    "    logits = h @ W2 + b2 # (32, 27)\n",
    "    loss = F.cross_entropy(logits, Y[ix]) # ALSO INDEXING INTO BATCH HERE\n",
    "    print(loss.item())\n",
    "    \n",
    "    # backward pass\n",
    "    for p in parameters:\n",
    "        p.grad = None\n",
    "    loss.backward()\n",
    "    \n",
    "    # update\n",
    "    lr = lrs[i]\n",
    "    for p in parameters:\n",
    "        p.data += -lr * p.grad\n",
    "        \n",
    "    # track learning rate stats\n",
    "    lri.append(lre[i])\n",
    "    lossi.append(loss.item())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d80d637",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(lri, lossi)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91bfc133",
   "metadata": {},
   "outputs": [],
   "source": [
    "# so 10 ** -1.0 or 0.1 is a pretty good learning rate\n",
    "# ... why exactly??"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ef99f41",
   "metadata": {},
   "outputs": [],
   "source": [
    "# let's check the loss on all the examples\n",
    "emb = C[X]    \n",
    "h = torch.tanh(emb.view(-1, 6) @ W1 + b1) # (32, 100)\n",
    "logits = h @ W2 + b2 # (32, 27)\n",
    "loss = F.cross_entropy(logits, Y)\n",
    "loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8481c1d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ----------------------------------------------------------------\n",
    "# iteration 6\n",
    "# ----------------------------------------------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "9f02abb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "g = torch.Generator().manual_seed(2 ** 31 - 1) # for reproducibility\n",
    "C = torch.randn((27, 2), generator=g)\n",
    "# hidden layer\n",
    "W1 = torch.randn((6, 100), generator=g) # weights\n",
    "b1 = torch.randn(100, generator=g) # biases\n",
    "# output layer (right?)\n",
    "W2 = torch.randn((100, 27), generator=g)\n",
    "b2 = torch.randn(27, generator=g)\n",
    "parameters = [C, W1, b1, W2, b2]\n",
    "\n",
    "for p in parameters:\n",
    "    p.requires_grad = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "2c2fc8b7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.24192525446414948\n"
     ]
    }
   ],
   "source": [
    "for _ in range(1000):   \n",
    "\n",
    "    #minibatch\n",
    "    ix = torch.randint(0, X.shape[0], (32,))\n",
    "\n",
    "    # forward pass    \n",
    "    emb = C[X[ix]]\n",
    "    \n",
    "    h = torch.tanh(emb.view(-1, 6) @ W1 + b1) # (32, 100)\n",
    "    logits = h @ W2 + b2 # (32, 27)\n",
    "    loss = F.cross_entropy(logits, Y[ix]) # ALSO INDEXING INTO BATCH HERE\n",
    "    #print(loss.item())\n",
    "    \n",
    "    # backward pass\n",
    "    for p in parameters:\n",
    "        p.grad = None\n",
    "    loss.backward()\n",
    "    \n",
    "    # update\n",
    "    lr = 0.01\n",
    "    for p in parameters:\n",
    "        p.data += -lr * p.grad\n",
    "\n",
    "print(loss.item())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "728eaed3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# after doing a lot of iterations at a certain learning rate, \"people like to\" do\n",
    "# what's called learning rate decay, i.e. lowering learning rate e.g. by a factor of 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "8d2f6c7f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.3218, grad_fn=<NllLossBackward0>)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# let's check the loss on all the examples\n",
    "emb = C[X]    \n",
    "h = torch.tanh(emb.view(-1, 6) @ W1 + b1) # (32, 100)\n",
    "logits = h @ W2 + b2 # (32, 27)\n",
    "loss = F.cross_entropy(logits, Y)\n",
    "loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "1ef05b3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# this looks good, because we got a much lower loss (2.28 compared to 2.45 (!))\n",
    "# however when we use increasingly complex models there becomes a greater danger of overfitting\n",
    "# therefore we should split the data into multiple batches:\n",
    "# 1. training split      80% -- to optimize parameters of the model\n",
    "# 2. dev/validate split  10% -- to optimize hyperparameters (e.g. size of hidden layer, size of embedding, etc.)\n",
    "# 3. test split          10% -- to evaluate performance at the very end (to avoid overfitting)\n",
    "# (roughly)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "9bb0781e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ----------------------------------------------------------------\n",
    "# iteration 6 -- TRAIN/TEST SPLIT (OH YEAH, TITLES ARE BACK!)\n",
    "# ----------------------------------------------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "75f46ab9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([182625, 3]) torch.Size([182625])\n",
      "torch.Size([22655, 3]) torch.Size([22655])\n",
      "torch.Size([22866, 3]) torch.Size([22866])\n"
     ]
    }
   ],
   "source": [
    "def build_dataset(words):\n",
    "    block_size = 3 # context length: how many characters do we take to predict the next one?\n",
    "               # original paper uses a cotext of 3 words\n",
    "    X, Y = [], []\n",
    "    for w in words:\n",
    "        context = [0] * block_size\n",
    "        for ch in w + '.':\n",
    "            ix = stoi[ch]\n",
    "            X.append(context)\n",
    "            Y.append(ix)\n",
    "            context = context[1:] + [ix] # crop first character and append, rolling window\n",
    "\n",
    "    X = torch.tensor(X)\n",
    "    Y = torch.tensor(Y)\n",
    "    print(X.shape, Y.shape)\n",
    "    return X, Y\n",
    "\n",
    "import random\n",
    "random.seed(42)\n",
    "random.shuffle(words)\n",
    "n1 = int(0.8*len(words))\n",
    "n2 = int(0.9*len(words))\n",
    "\n",
    "Xtr, Ytr = build_dataset(words[:n1])\n",
    "Xdev, Ydev = build_dataset(words[n1:n2])\n",
    "Xte, Yte = build_dataset(words[n2:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "8f2fdb13",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([182625, 3]), torch.int64, torch.Size([182625]), torch.int64)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Xtr.shape, Xtr.dtype, Ytr.shape, Ytr.dtype   # new dataset attributes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "9d6f08e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "g = torch.Generator().manual_seed(2 ** 31 - 1) # for reproducibility\n",
    "C = torch.randn((27, 2), generator=g)\n",
    "# hidden layer\n",
    "W1 = torch.randn((6, 100), generator=g) # weights\n",
    "b1 = torch.randn(100, generator=g) # biases\n",
    "# output layer (right?)\n",
    "W2 = torch.randn((100, 27), generator=g)\n",
    "b2 = torch.randn(27, generator=g)\n",
    "parameters = [C, W1, b1, W2, b2]\n",
    "\n",
    "for p in parameters:\n",
    "    p.requires_grad = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "70b0895c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3.031980514526367\n"
     ]
    }
   ],
   "source": [
    "for _ in range(10000):   \n",
    "\n",
    "    #minibatch\n",
    "    ix = torch.randint(0, Xtr.shape[0], (32,))\n",
    "\n",
    "    # forward pass    \n",
    "    emb = C[Xtr[ix]]\n",
    "    \n",
    "    h = torch.tanh(emb.view(-1, 6) @ W1 + b1) # (32, 100)\n",
    "    logits = h @ W2 + b2 # (32, 27)\n",
    "    loss = F.cross_entropy(logits, Ytr[ix]) # ALSO INDEXING INTO BATCH HERE\n",
    "    #print(loss.item())\n",
    "    \n",
    "    # backward pass\n",
    "    for p in parameters:\n",
    "        p.grad = None\n",
    "    loss.backward()\n",
    "    \n",
    "    # update\n",
    "    lr = 0.01\n",
    "    for p in parameters:\n",
    "        p.data += -lr * p.grad\n",
    "\n",
    "print(loss.item ())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "f5aafc86",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(2.5639, grad_fn=<NllLossBackward0>)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "emb = C[Xdev]    \n",
    "h = torch.tanh(emb.view(-1, 6) @ W1 + b1) # (32, 100)\n",
    "logits = h @ W2 + b2 # (32, 27)\n",
    "loss = F.cross_entropy(logits, Ydev)\n",
    "loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "29c2fce8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(2.5693, grad_fn=<NllLossBackward0>)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "emb = C[Xtr]    \n",
    "h = torch.tanh(emb.view(-1, 6) @ W1 + b1) # (32, 100)\n",
    "logits = h @ W2 + b2 # (32, 27)\n",
    "loss = F.cross_entropy(logits, Ytr)\n",
    "loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "be7d3ed3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# as we see the dev and training loss are both roughly equal.\n",
    "# we're not overfitting.\n",
    "# according to Andrej, we're actually underfitting\n",
    "# so let's BEEF up those parameters!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "af378008",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.3855, -0.3094],\n",
       "        [ 0.1915, -0.3524],\n",
       "        [ 0.0054, -0.2830],\n",
       "        [-0.0558, -0.3448],\n",
       "        [-0.1479, -0.3297],\n",
       "        [ 0.1020, -0.3132],\n",
       "        [-0.1356, -0.3468],\n",
       "        [ 0.4918,  2.3182],\n",
       "        [-0.1914, -0.2304],\n",
       "        [-0.0098, -0.3318],\n",
       "        [-0.2634, -0.3320],\n",
       "        [-0.1862, -0.3411],\n",
       "        [ 0.3739,  2.1840],\n",
       "        [-0.2378, -0.2958],\n",
       "        [-0.1341, -0.1909],\n",
       "        [ 0.1308, -0.3527],\n",
       "        [ 0.3356,  2.0098],\n",
       "        [-0.3106, -0.5611],\n",
       "        [-0.2049, -0.3302],\n",
       "        [-0.0267, -0.4137],\n",
       "        [-0.1287, -0.4183],\n",
       "        [ 0.5165,  2.2625],\n",
       "        [-0.2649, -0.3766],\n",
       "        [-0.2109, -0.3993],\n",
       "        [-0.1846, -0.2327],\n",
       "        [-0.0642, -0.2249],\n",
       "        [-0.2041, -0.3225]], requires_grad=True)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "C"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "97b9fcd1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ----------------------------------------------------------------\n",
    "# iteration 6 -- MORE PARAMETERS\n",
    "# ----------------------------------------------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "75fd0a1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "g = torch.Generator().manual_seed(2 ** 31 - 1) # for reproducibility\n",
    "C = torch.randn((27, 2), generator=g)\n",
    "# hidden layer\n",
    "W1 = torch.randn((6, 300), generator=g) # weights\n",
    "b1 = torch.randn(300, generator=g) # biases\n",
    "# output layer (right?)\n",
    "W2 = torch.randn((300, 27), generator=g)\n",
    "b2 = torch.randn(27, generator=g)\n",
    "parameters = [C, W1, b1, W2, b2]\n",
    "\n",
    "for p in parameters:\n",
    "    p.requires_grad = True\n",
    "    \n",
    "# easiest way to increase the size of the nerual net is to increase the size of the hidden layer (27,100) -> (27,300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "7c974aa1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10281"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum(p.nelement() for p in parameters) # number of parameters in total"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "815a78a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#lri = []\n",
    "#lossi = []\n",
    "#stepi = []\n",
    "\n",
    "for i in range(10000):   \n",
    "\n",
    "    #minibatch\n",
    "    ix = torch.randint(0, Xtr.shape[0], (32,))\n",
    "\n",
    "    # forward pass    \n",
    "    emb = C[Xtr[ix]]\n",
    "    \n",
    "    h = torch.tanh(emb.view(-1, 6) @ W1 + b1) # (32, 100)\n",
    "    logits = h @ W2 + b2 # (32, 27)\n",
    "    loss = F.cross_entropy(logits, Ytr[ix]) # ALSO INDEXING INTO BATCH HERE\n",
    "    #print(loss.item())\n",
    "    \n",
    "    # backward pass\n",
    "    for p in parameters:\n",
    "        p.grad = None\n",
    "    loss.backward()\n",
    "    \n",
    "    # update\n",
    "    lr = 0.01\n",
    "    for p in parameters:\n",
    "        p.data += -lr * p.grad\n",
    "        \n",
    "    # track stats\n",
    "    #lri.append(lre[i])\n",
    "    #stepi.append(i)\n",
    "    #lossi.append(loss.item())\n",
    "\n",
    "\n",
    "#print(loss.item())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "15a845d8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(2.5198, grad_fn=<NllLossBackward0>)"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "emb = C[Xdev]    \n",
    "h = torch.tanh(emb.view(-1, 6) @ W1 + b1) # (32, 100)\n",
    "logits = h @ W2 + b2 # (32, 27)\n",
    "loss = F.cross_entropy(logits, Ydev)\n",
    "loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "f089aa01",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(2.5293, grad_fn=<NllLossBackward0>)"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "emb = C[Xtr]    \n",
    "h = torch.tanh(emb.view(-1, 6) @ W1 + b1) # (32, 100)\n",
    "logits = h @ W2 + b2 # (32, 27)\n",
    "loss = F.cross_entropy(logits, Ytr)\n",
    "loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "27de6dfd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 800x800 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize=(8,8))\n",
    "plt.scatter(C[:,0].data, C[:,1].data, s=200)\n",
    "for i in range(C.shape[0]):\n",
    "    plt.text(C[i,0].item(), C[i,1].item(), itos[i], ha=\"center\", va=\"center\", color=\"white\")\n",
    "plt.grid('minor')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "39f90786",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ----------------------------------------------------------------\n",
    "# iteration 7 -- MORE (MORE) PARAMETERS\n",
    "# ----------------------------------------------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "a929eee9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# this time we're going to increase the size of the embeddings...\n",
    "# (and slightly decrease the size of the hidden layer)\n",
    "\n",
    "g = torch.Generator().manual_seed(2 ** 31 - 1) # for reproducibility\n",
    "C = torch.randn((27, 10), generator=g)\n",
    "# hidden layer\n",
    "W1 = torch.randn((30, 200), generator=g) # weights\n",
    "b1 = torch.randn(200, generator=g) # biases\n",
    "# output layer (right?)\n",
    "W2 = torch.randn((200, 27), generator=g)\n",
    "b2 = torch.randn(27, generator=g)\n",
    "parameters = [C, W1, b1, W2, b2]\n",
    "\n",
    "for p in parameters:\n",
    "    p.requires_grad = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "946784ec",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "11897"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum(p.nelement() for p in parameters) # number of parameters in total"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "58c45496",
   "metadata": {},
   "outputs": [],
   "source": [
    "#lri = []\n",
    "#lossi = []\n",
    "#stepi = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "7fd4aa05",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n"
     ]
    }
   ],
   "source": [
    "for i in range(1000):   \n",
    "\n",
    "    if i % 1000 == 0:\n",
    "        print(i)\n",
    "    \n",
    "    #minibatch\n",
    "    ix = torch.randint(0, Xtr.shape[0], (256,))\n",
    "\n",
    "    # forward pass    \n",
    "    emb = C[Xtr[ix]]\n",
    "    \n",
    "    h = torch.tanh(emb.view(-1, 30) @ W1 + b1) # (32, 100)\n",
    "    logits = h @ W2 + b2 # (32, 27)\n",
    "    loss = F.cross_entropy(logits, Ytr[ix]) # ALSO INDEXING INTO BATCH HERE\n",
    "    #print(loss.item())\n",
    "    \n",
    "    # backward pass\n",
    "    for p in parameters:\n",
    "        p.grad = None\n",
    "    loss.backward()\n",
    "    \n",
    "    # update\n",
    "    lr = 0.01\n",
    "    for p in parameters:\n",
    "        p.data += -lr * p.grad\n",
    "        \n",
    "    # track stats\n",
    "    #lri.append(lre[i])\n",
    "    #stepi.append(i)\n",
    "    #lossi.append(loss.log10().item())\n",
    "\n",
    "\n",
    "#print(loss.item())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "7f41deff",
   "metadata": {},
   "outputs": [],
   "source": [
    "#plt.plot(stepi, lossi)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "8df2b413",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(2.1912, grad_fn=<NllLossBackward0>)"
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "emb = C[Xdev]    \n",
    "h = torch.tanh(emb.view(-1, 30) @ W1 + b1) # (32, 100)\n",
    "logits = h @ W2 + b2 # (32, 27)\n",
    "loss = F.cross_entropy(logits, Ydev)\n",
    "loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "3c926ad1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(2.1667, grad_fn=<NllLossBackward0>)"
      ]
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "emb = C[Xtr]    \n",
    "h = torch.tanh(emb.view(-1, 30) @ W1 + b1) # (32, 100)\n",
    "logits = h @ W2 + b2 # (32, 27)\n",
    "loss = F.cross_entropy(logits, Ytr)\n",
    "loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "00327e1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# SAMPLING FROM THE MODEL !!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "3f61ea3e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mora.\n",
      "mayanniee.\n",
      "mad.\n",
      "rylle.\n",
      "emmancendraek.\n",
      "adelynnelin.\n",
      "shy.\n",
      "jen.\n",
      "edennestanaraelynn.\n",
      "houra.\n",
      "noshibergihimiest.\n",
      "jair.\n",
      "jenslen.\n",
      "pulfzun.\n",
      "macdariyah.\n",
      "faeha.\n",
      "kaysh.\n",
      "samyah.\n",
      "hal.\n",
      "salynn.\n",
      "juluan.\n",
      "leouren.\n",
      "cre.\n",
      "kaveaisten.\n",
      "adi.\n",
      "fen.\n",
      "oewen.\n",
      "zorie.\n",
      "samuey.\n",
      "con.\n",
      "reon.\n",
      "isa.\n",
      "iri.\n",
      "evon.\n",
      "walla.\n",
      "ortaraszin.\n",
      "desist.\n",
      "alingt.\n",
      "dabilin.\n",
      "aimellakeyanni.\n",
      "sxavin.\n",
      "damariennccayne.\n",
      "aud.\n",
      "aiwe.\n",
      "dah.\n",
      "virley.\n",
      "jayerancoo.\n",
      "grellya.\n",
      "iimarilon.\n",
      "ellah.\n"
     ]
    }
   ],
   "source": [
    "g = torch.Generator().manual_seed(2 ** 31 - 1 + 10)\n",
    "\n",
    "for _ in range(50):\n",
    "    \n",
    "    out = []\n",
    "    context = [0] * block_size\n",
    "    while True:\n",
    "        emb = C[torch.tensor([context])]\n",
    "        h = torch.tanh(emb.view(1, -1) @ W1 + b1)\n",
    "        logits = h @ W2 + b2\n",
    "        probs = F.softmax(logits, dim=1)\n",
    "        ix = torch.multinomial(probs, num_samples=1, generator=g).item()\n",
    "        context = context[1:] + [ix]\n",
    "        out.append(ix)\n",
    "        if ix == 0:\n",
    "            break\n",
    "\n",
    "    print(''.join(itos[i] for i in out))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30ba07e7-3a3d-4b9e-a01e-c04e56a2beb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# best test loss from the video is 2.1701\n",
    "# exercise to reader is get a better loss using this model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53d34461-64d0-45a4-aef2-214151e08c41",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ----------------------------------------------------------------\n",
    "# iter 8\n",
    "# ----------------------------------------------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "id": "8d776920-278f-4fe0-846d-cee3f3e77c3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# this time we're going to increase the size of the embeddings...\n",
    "# (and slightly decrease the size of the hidden layer)\n",
    "\n",
    "g = torch.Generator().manual_seed(2 ** 31 - 1) # for reproducibility\n",
    "C = torch.randn((27, 4), generator=g)\n",
    "# hidden layer\n",
    "W1 = torch.randn((12, 300), generator=g) # weights\n",
    "b1 = torch.randn(300, generator=g) # biases\n",
    "# output layer (right?)\n",
    "W2 = torch.randn((300, 27), generator=g)\n",
    "b2 = torch.randn(27, generator=g)\n",
    "parameters = [C, W1, b1, W2, b2]\n",
    "\n",
    "for p in parameters:\n",
    "    p.requires_grad = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "id": "3182de6a-f26a-495a-aada-f68be1d69f5a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "12135"
      ]
     },
     "execution_count": 120,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum(p.nelement() for p in parameters) # number of parameters in total"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "id": "55146fa2-e378-40d5-b77a-da1b8b1ecd09",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0: 2.115422010421753\n",
      "1000: 2.2850892543792725\n",
      "2000: 2.448554515838623\n",
      "3000: 2.2070627212524414\n",
      "4000: 2.0405824184417725\n",
      "5000: 2.063225507736206\n",
      "6000: 2.068718910217285\n",
      "7000: 2.4837722778320312\n",
      "8000: 2.2944014072418213\n",
      "9000: 2.245450973510742\n",
      "10000: 2.367769718170166\n",
      "11000: 2.3223841190338135\n",
      "12000: 2.012387275695801\n",
      "13000: 1.904250144958496\n",
      "14000: 2.2287001609802246\n",
      "15000: 2.007561206817627\n",
      "16000: 2.0154168605804443\n",
      "17000: 2.323148012161255\n",
      "18000: 2.0671329498291016\n",
      "19000: 2.1220552921295166\n",
      "20000: 2.242379665374756\n",
      "21000: 2.3672664165496826\n",
      "22000: 2.0212714672088623\n",
      "23000: 2.203503370285034\n",
      "24000: 2.4236955642700195\n",
      "25000: 1.9961293935775757\n",
      "26000: 2.050748586654663\n",
      "27000: 2.0382094383239746\n",
      "28000: 2.001460313796997\n",
      "29000: 2.073377847671509\n",
      "30000: 2.3961193561553955\n",
      "31000: 2.2380309104919434\n",
      "32000: 2.327364683151245\n",
      "33000: 2.3748645782470703\n",
      "34000: 2.3117423057556152\n",
      "35000: 2.3180580139160156\n",
      "36000: 2.0150034427642822\n",
      "37000: 2.0387368202209473\n",
      "38000: 2.348905086517334\n",
      "39000: 2.130556583404541\n",
      "40000: 2.049065113067627\n",
      "41000: 2.2776763439178467\n",
      "42000: 2.187685012817383\n",
      "43000: 2.3770017623901367\n",
      "44000: 2.0712361335754395\n",
      "45000: 2.2530932426452637\n",
      "46000: 1.825695276260376\n",
      "47000: 2.255354404449463\n",
      "48000: 1.9639002084732056\n",
      "49000: 2.289019823074341\n"
     ]
    }
   ],
   "source": [
    "for i in range(50000):   \n",
    "    \n",
    "    #minibatch\n",
    "    ix = torch.randint(0, Xtr.shape[0], (64,))\n",
    "\n",
    "    # forward pass    \n",
    "    emb = C[Xtr[ix]]\n",
    "    \n",
    "    h = torch.tanh(emb.view(-1, 12) @ W1 + b1) # (32, 100)\n",
    "    logits = h @ W2 + b2 # (32, 27)\n",
    "    loss = F.cross_entropy(logits, Ytr[ix]) # ALSO INDEXING INTO BATCH HERE\n",
    "\n",
    "    if i % 1000 == 0:\n",
    "        print(f'{i}: {loss.item()}')\n",
    "    #print(loss.item())\n",
    "    \n",
    "    # backward pass\n",
    "    for p in parameters:\n",
    "        p.grad = None\n",
    "    loss.backward()\n",
    "    \n",
    "    # update\n",
    "    lr = 0.001\n",
    "    for p in parameters:\n",
    "        p.data += -lr * p.grad\n",
    "        \n",
    "    # track stats\n",
    "    #lri.append(lre[i])\n",
    "    #stepi.append(i)\n",
    "    #lossi.append(loss.log10().item())\n",
    "\n",
    "\n",
    "#print(loss.item())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "id": "41818cff-f2f9-4029-ae4f-f38f80b3800f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(2.2189, grad_fn=<NllLossBackward0>)"
      ]
     },
     "execution_count": 150,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "emb = C[Xdev]    \n",
    "h = torch.tanh(emb.view(-1, 12) @ W1 + b1) # (32, 100)\n",
    "logits = h @ W2 + b2 # (32, 27)\n",
    "loss = F.cross_entropy(logits, Ydev)\n",
    "loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7258b3e6-69a5-4909-b710-e47ca513cf85",
   "metadata": {},
   "outputs": [],
   "source": [
    "# best loss I seem to be able to get is 2.2189"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "id": "9f47cf42-d5f6-45fb-b25a-0bd6db2de67e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mora.\n",
      "mayanniee.\n",
      "med.\n",
      "ryla.\n",
      "rethrelengrlee.\n",
      "aderydaelin.\n",
      "shyone.\n",
      "leigh.\n",
      "estanar.\n",
      "kayzioh.\n",
      "kamin.\n",
      "shubrrgyni.\n",
      "jest.\n",
      "jair.\n",
      "jelionn.\n",
      "paitoun.\n",
      "mace.\n",
      "ryyah.\n",
      "faeh.\n",
      "yuve.\n",
      "myonnyamihalina.\n",
      "yansun.\n",
      "zakelveuren.\n",
      "cre.\n",
      "kiveaon.\n",
      "marid.\n",
      "jahnise.\n",
      "ban.\n",
      "prick.\n",
      "amuez.\n",
      "con.\n",
      "reon.\n",
      "isa.\n",
      "iri.\n",
      "evondwhlan.\n",
      "ortaraszin.\n",
      "desiah.\n",
      "alingtelvissivia.\n",
      "meliaketarriy.\n",
      "xavin.\n",
      "damaitenickarionaud.\n",
      "aive.\n",
      "dih.\n",
      "virle.\n",
      "ajalena.\n",
      "moiah.\n",
      "rictaviiah.\n",
      "glon.\n",
      "ethayderlon.\n",
      "jairy.\n"
     ]
    }
   ],
   "source": [
    "g = torch.Generator().manual_seed(2 ** 31 - 1 + 10)\n",
    "\n",
    "for _ in range(50):\n",
    "    \n",
    "    out = []\n",
    "    context = [0] * block_size\n",
    "    while True:\n",
    "        emb = C[torch.tensor([context])]\n",
    "        h = torch.tanh(emb.view(1, -1) @ W1 + b1)\n",
    "        logits = h @ W2 + b2\n",
    "        probs = F.softmax(logits, dim=1)\n",
    "        ix = torch.multinomial(probs, num_samples=1, generator=g).item()\n",
    "        context = context[1:] + [ix]\n",
    "        out.append(ix)\n",
    "        if ix == 0:\n",
    "            break\n",
    "\n",
    "    print(''.join(itos[i] for i in out))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cad71513-729f-4733-a207-2684ba165214",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ----------------------------------------------------------------\n",
    "# iter 8\n",
    "# ----------------------------------------------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "id": "98d723ba-c962-4244-9096-74efedf46492",
   "metadata": {},
   "outputs": [],
   "source": [
    "# this time we're going to increase the size of the embeddings...\n",
    "# (and slightly decrease the size of the hidden layer)\n",
    "\n",
    "g = torch.Generator().manual_seed(2 ** 31 - 1) # for reproducibility\n",
    "C = torch.randn((27, 10), generator=g)\n",
    "# hidden layer\n",
    "W1 = torch.randn((30, 150), generator=g) # weights\n",
    "b1 = torch.randn(150, generator=g) # biases\n",
    "# output layer (right?)\n",
    "W2 = torch.randn((150, 27), generator=g)\n",
    "b2 = torch.randn(27, generator=g)\n",
    "parameters = [C, W1, b1, W2, b2]\n",
    "\n",
    "for p in parameters:\n",
    "    p.requires_grad = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "id": "f24c03ab-106c-42f4-a695-48533603a2a9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8997"
      ]
     },
     "execution_count": 153,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum(p.nelement() for p in parameters) # number of parameters in total"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "id": "089b69ed-f27a-4f80-9d32-3a65de1dfcc3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#lri = []\n",
    "lossi = []\n",
    "stepi = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 235,
   "id": "197061c6-998a-4d18-9710-19acd2685247",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0: 2.1193010807037354\n",
      "100: 2.1520023345947266\n",
      "200: 2.204747200012207\n",
      "300: 2.1593122482299805\n",
      "400: 2.093663215637207\n",
      "500: 2.0906312465667725\n",
      "600: 2.178438663482666\n",
      "700: 2.159015417098999\n",
      "800: 2.092186689376831\n",
      "900: 2.1526906490325928\n",
      "1000: 2.0854556560516357\n",
      "1100: 2.232177257537842\n",
      "1200: 2.12353515625\n",
      "1300: 2.157930612564087\n",
      "1400: 2.150251626968384\n",
      "1500: 2.0945663452148438\n",
      "1600: 2.084001064300537\n",
      "1700: 2.0780463218688965\n",
      "1800: 2.2673988342285156\n",
      "1900: 2.1284596920013428\n",
      "2000: 2.131715774536133\n",
      "2100: 2.130709409713745\n",
      "2200: 2.135843276977539\n",
      "2300: 2.095097541809082\n",
      "2400: 2.136087656021118\n",
      "2500: 2.1322505474090576\n",
      "2600: 2.1583902835845947\n",
      "2700: 2.136890172958374\n",
      "2800: 2.1116011142730713\n",
      "2900: 2.1519131660461426\n",
      "3000: 2.2225863933563232\n",
      "3100: 2.1293132305145264\n",
      "3200: 2.215528964996338\n",
      "3300: 2.1937143802642822\n",
      "3400: 2.15860652923584\n",
      "3500: 2.140834331512451\n",
      "3600: 2.1777970790863037\n",
      "3700: 2.1546807289123535\n",
      "3800: 2.159527063369751\n",
      "3900: 2.184126138687134\n",
      "4000: 2.0617079734802246\n",
      "4100: 2.1829538345336914\n",
      "4200: 2.1271140575408936\n",
      "4300: 2.1318204402923584\n",
      "4400: 2.1953141689300537\n",
      "4500: 2.1351218223571777\n",
      "4600: 2.1559019088745117\n",
      "4700: 2.14149808883667\n",
      "4800: 2.2029597759246826\n",
      "4900: 2.0992257595062256\n",
      "5000: 2.1721043586730957\n",
      "5100: 2.1891252994537354\n",
      "5200: 2.136935234069824\n",
      "5300: 2.1436471939086914\n",
      "5400: 2.1006855964660645\n",
      "5500: 2.17746639251709\n",
      "5600: 2.104562282562256\n",
      "5700: 2.215820074081421\n",
      "5800: 2.130066156387329\n",
      "5900: 2.110252618789673\n",
      "6000: 2.1559195518493652\n",
      "6100: 2.142388105392456\n",
      "6200: 2.1800405979156494\n",
      "6300: 2.1207077503204346\n",
      "6400: 2.1771371364593506\n",
      "6500: 2.140667676925659\n",
      "6600: 2.155961036682129\n",
      "6700: 2.2187485694885254\n",
      "6800: 2.1507999897003174\n",
      "6900: 2.20849609375\n",
      "7000: 2.1494908332824707\n",
      "7100: 2.1546823978424072\n",
      "7200: 2.1843268871307373\n",
      "7300: 2.239825487136841\n",
      "7400: 2.065793991088867\n",
      "7500: 2.214393377304077\n",
      "7600: 2.134194850921631\n",
      "7700: 2.1960859298706055\n",
      "7800: 2.136823892593384\n",
      "7900: 2.184112310409546\n",
      "8000: 2.1257753372192383\n",
      "8100: 2.112886667251587\n",
      "8200: 2.1048357486724854\n",
      "8300: 2.157949924468994\n",
      "8400: 2.1280386447906494\n",
      "8500: 2.1093289852142334\n",
      "8600: 2.1142799854278564\n",
      "8700: 2.1735830307006836\n",
      "8800: 2.1424362659454346\n",
      "8900: 2.122025728225708\n",
      "9000: 2.1247918605804443\n",
      "9100: 2.0890908241271973\n",
      "9200: 2.1483700275421143\n",
      "9300: 2.143639087677002\n",
      "9400: 2.1565144062042236\n",
      "9500: 2.1753668785095215\n",
      "9600: 2.156737804412842\n",
      "9700: 2.17470121383667\n",
      "9800: 2.1732282638549805\n",
      "9900: 2.1290717124938965\n"
     ]
    }
   ],
   "source": [
    "for i in range(10000):   \n",
    "    \n",
    "    #minibatch\n",
    "    ix = torch.randint(0, Xtr.shape[0], (1000,))\n",
    "\n",
    "    # forward pass    \n",
    "    emb = C[Xtr[ix]]\n",
    "    \n",
    "    h = torch.tanh(emb.view(-1, 30) @ W1 + b1) # (32, 100)\n",
    "    logits = h @ W2 + b2 # (32, 27)\n",
    "    loss = F.cross_entropy(logits, Ytr[ix]) # ALSO INDEXING INTO BATCH HERE\n",
    "\n",
    "    if i % 100 == 0:\n",
    "        print(f'{i}: {loss.item()}')\n",
    "    #print(loss.item())\n",
    "    \n",
    "    # backward pass\n",
    "    for p in parameters:\n",
    "        p.grad = None\n",
    "    loss.backward()\n",
    "    \n",
    "    # update\n",
    "    lr = 0.1\n",
    "    for p in parameters:\n",
    "        p.data += -lr * p.grad\n",
    "        \n",
    "    # track stats\n",
    "    #lri.append(lre[i])\n",
    "    stepi.append(i)\n",
    "    lossi.append(loss.log10().item())\n",
    "\n",
    "\n",
    "#print(loss.item())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 236,
   "id": "37d1c988-6779-4e43-ab01-3a891ce19c1f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x7fe78ce2dd90>]"
      ]
     },
     "execution_count": 236,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(stepi, lossi)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 237,
   "id": "af14b538-c312-4583-b079-58f880247ccc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(2.1748, grad_fn=<NllLossBackward0>)"
      ]
     },
     "execution_count": 237,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "emb = C[Xdev]    \n",
    "h = torch.tanh(emb.view(-1, 30) @ W1 + b1) # (32, 100)\n",
    "logits = h @ W2 + b2 # (32, 27)\n",
    "loss = F.cross_entropy(logits, Ydev)\n",
    "loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 238,
   "id": "227f7d66-988f-4eb8-ab9b-601a282587d3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(2.1448, grad_fn=<NllLossBackward0>)"
      ]
     },
     "execution_count": 238,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "emb = C[Xtr]    \n",
    "h = torch.tanh(emb.view(-1, 30) @ W1 + b1) # (32, 100)\n",
    "logits = h @ W2 + b2 # (32, 27)\n",
    "loss = F.cross_entropy(logits, Ytr)\n",
    "loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "015fff47-13d9-482f-b9fc-94e7ade805ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "# best loss is 2.14 ??"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 239,
   "id": "ff936904-b73f-4d2d-b4c7-ac1ab314772f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mora.\n",
      "kayah.\n",
      "see.\n",
      "med.\n",
      "rylla.\n",
      "emmruttadrlee.\n",
      "adelynneliah.\n",
      "milopi.\n",
      "eden.\n",
      "estanara.\n",
      "myki.\n",
      "hotalin.\n",
      "sher.\n",
      "roshiriel.\n",
      "kinto.\n",
      "jenslen.\n",
      "parrius.\n",
      "kynder.\n",
      "yadleyel.\n",
      "yume.\n",
      "myskeyla.\n",
      "hal.\n",
      "salyansuf.\n",
      "zakhloe.\n",
      "ren.\n",
      "crevis.\n",
      "jaiel.\n",
      "pordin.\n",
      "kyloe.\n",
      "bayziei.\n",
      "jorettyn.\n",
      "kharlo.\n",
      "jian.\n",
      "iri.\n",
      "evon.\n",
      "walla.\n",
      "ortarashten.\n",
      "goela.\n",
      "alitan.\n",
      "debil.\n",
      "vid.\n",
      "mellanetarriy.\n",
      "xavi.\n",
      "jakelizenickayionald.\n",
      "aive.\n",
      "dihevirley.\n",
      "jayena.\n",
      "moialorictamiia.\n",
      "jolon.\n",
      "ethayderlina.\n"
     ]
    }
   ],
   "source": [
    "g = torch.Generator().manual_seed(2 ** 31 - 1 + 10)\n",
    "\n",
    "for _ in range(50):\n",
    "    \n",
    "    out = []\n",
    "    context = [0] * block_size\n",
    "    while True:\n",
    "        emb = C[torch.tensor([context])]\n",
    "        h = torch.tanh(emb.view(1, -1) @ W1 + b1)\n",
    "        logits = h @ W2 + b2\n",
    "        probs = F.softmax(logits, dim=1)\n",
    "        ix = torch.multinomial(probs, num_samples=1, generator=g).item()\n",
    "        context = context[1:] + [ix]\n",
    "        out.append(ix)\n",
    "        if ix == 0:\n",
    "            break\n",
    "\n",
    "    print(''.join(itos[i] for i in out))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22426312-4077-400f-8573-89975cd4d36a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ----------------------------------------------------------------\n",
    "# iter 9 -- let's try more context!!\n",
    "# ----------------------------------------------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 402,
   "id": "dc4fda39-744d-4d26-b000-f1249d8e3fa6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([182456, 8]) torch.Size([182456])\n",
      "torch.Size([22752, 8]) torch.Size([22752])\n",
      "torch.Size([22938, 8]) torch.Size([22938])\n"
     ]
    }
   ],
   "source": [
    "block_size = 8 # context length: how many characters do we take to predict the next one?\n",
    "               # original paper uses a cotext of 3 words\n",
    "\n",
    "def build_dataset(words):\n",
    "    X, Y = [], []\n",
    "    for w in words:\n",
    "        context = [0] * block_size\n",
    "        for ch in w + '.':\n",
    "            ix = stoi[ch]\n",
    "            X.append(context)\n",
    "            Y.append(ix)\n",
    "            context = context[1:] + [ix] # crop first character and append, rolling window\n",
    "\n",
    "    X = torch.tensor(X)\n",
    "    Y = torch.tensor(Y)\n",
    "    print(X.shape, Y.shape)\n",
    "    return X, Y\n",
    "\n",
    "import random\n",
    "random.seed(42)\n",
    "random.shuffle(words)\n",
    "n1 = int(0.8*len(words))\n",
    "n2 = int(0.9*len(words))\n",
    "\n",
    "Xtr, Ytr = build_dataset(words[:n1])\n",
    "Xdev, Ydev = build_dataset(words[n1:n2])\n",
    "Xte, Yte = build_dataset(words[n2:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 403,
   "id": "9b91765e-1880-4ea8-955d-59b605bfe0f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "g = torch.Generator().manual_seed(2 ** 31 - 1) # for reproducibility\n",
    "C = torch.randn((27, 5), generator=g)\n",
    "# hidden layer\n",
    "W1 = torch.randn((40, 100), generator=g) # weights\n",
    "b1 = torch.randn(100, generator=g) # biases\n",
    "# output layer (right?)\n",
    "W2 = torch.randn((100, 27), generator=g)\n",
    "b2 = torch.randn(27, generator=g)\n",
    "parameters = [C, W1, b1, W2, b2]\n",
    "\n",
    "for p in parameters:\n",
    "    p.requires_grad = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 404,
   "id": "2050efe3-a412-42b7-bfd1-28998f903cca",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6962"
      ]
     },
     "execution_count": 404,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum(p.nelement() for p in parameters) # number of parameters in total"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 436,
   "id": "041193ea-28df-477e-805d-14eb6b43e11b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0: 2.3255388736724854\n",
      "100: 2.3185596466064453\n",
      "200: 2.266429901123047\n",
      "300: 2.3607137203216553\n",
      "400: 2.2683298587799072\n",
      "500: 2.322235584259033\n",
      "600: 2.295442819595337\n",
      "700: 2.3104755878448486\n",
      "800: 2.282677173614502\n",
      "900: 2.270017385482788\n",
      "1000: 2.239888906478882\n",
      "1100: 2.3697705268859863\n",
      "1200: 2.2212793827056885\n",
      "1300: 2.32245135307312\n",
      "1400: 2.3299078941345215\n",
      "1500: 2.3041253089904785\n",
      "1600: 2.238553047180176\n",
      "1700: 2.2814693450927734\n",
      "1800: 2.338242530822754\n",
      "1900: 2.2348952293395996\n",
      "2000: 2.286409854888916\n",
      "2100: 2.29797101020813\n",
      "2200: 2.2634520530700684\n",
      "2300: 2.269585371017456\n",
      "2400: 2.31355357170105\n",
      "2500: 2.357513904571533\n",
      "2600: 2.1928603649139404\n",
      "2700: 2.2710089683532715\n",
      "2800: 2.323629140853882\n",
      "2900: 2.2475507259368896\n",
      "3000: 2.2773640155792236\n",
      "3100: 2.2593796253204346\n",
      "3200: 2.3024513721466064\n",
      "3300: 2.258265733718872\n",
      "3400: 2.303119659423828\n",
      "3500: 2.281431198120117\n",
      "3600: 2.326287031173706\n",
      "3700: 2.2870404720306396\n",
      "3800: 2.338315963745117\n",
      "3900: 2.33196759223938\n",
      "4000: 2.252747058868408\n",
      "4100: 2.2524728775024414\n",
      "4200: 2.318753957748413\n",
      "4300: 2.301090955734253\n",
      "4400: 2.307453155517578\n",
      "4500: 2.3356194496154785\n",
      "4600: 2.243673801422119\n",
      "4700: 2.2802722454071045\n",
      "4800: 2.3160204887390137\n",
      "4900: 2.3085203170776367\n",
      "5000: 2.333019733428955\n",
      "5100: 2.3041763305664062\n",
      "5200: 2.308865785598755\n",
      "5300: 2.358410596847534\n",
      "5400: 2.3137757778167725\n",
      "5500: 2.363126277923584\n",
      "5600: 2.2281510829925537\n",
      "5700: 2.3128750324249268\n",
      "5800: 2.264896869659424\n",
      "5900: 2.249565839767456\n",
      "6000: 2.28576922416687\n",
      "6100: 2.2507708072662354\n",
      "6200: 2.3319509029388428\n",
      "6300: 2.176737070083618\n",
      "6400: 2.3218748569488525\n",
      "6500: 2.3374814987182617\n",
      "6600: 2.35123872756958\n",
      "6700: 2.266542434692383\n",
      "6800: 2.3007304668426514\n",
      "6900: 2.3587722778320312\n",
      "7000: 2.3447017669677734\n",
      "7100: 2.316348075866699\n",
      "7200: 2.3259706497192383\n",
      "7300: 2.353896379470825\n",
      "7400: 2.309939384460449\n",
      "7500: 2.2910358905792236\n",
      "7600: 2.2267301082611084\n",
      "7700: 2.2565014362335205\n",
      "7800: 2.2769298553466797\n",
      "7900: 2.3391497135162354\n",
      "8000: 2.3281173706054688\n",
      "8100: 2.3113811016082764\n",
      "8200: 2.3781301975250244\n",
      "8300: 2.3573622703552246\n",
      "8400: 2.2678041458129883\n",
      "8500: 2.277805805206299\n",
      "8600: 2.238140821456909\n",
      "8700: 2.278149366378784\n",
      "8800: 2.2655038833618164\n",
      "8900: 2.306985855102539\n",
      "9000: 2.281338930130005\n",
      "9100: 2.3158414363861084\n",
      "9200: 2.2928080558776855\n",
      "9300: 2.2748398780822754\n",
      "9400: 2.2761101722717285\n",
      "9500: 2.2532095909118652\n",
      "9600: 2.2551681995391846\n",
      "9700: 2.247154951095581\n",
      "9800: 2.2843735218048096\n",
      "9900: 2.2859182357788086\n"
     ]
    }
   ],
   "source": [
    "for i in range(10000):   \n",
    "    \n",
    "    #minibatch\n",
    "    ix = torch.randint(0, Xtr.shape[0], (1000,))\n",
    "\n",
    "    # forward pass    \n",
    "    emb = C[Xtr[ix]]\n",
    "    \n",
    "    h = torch.tanh(emb.view(-1, 40) @ W1 + b1) # (32, 100)\n",
    "    logits = h @ W2 + b2 # (32, 27)\n",
    "    loss = F.cross_entropy(logits, Ytr[ix]) # ALSO INDEXING INTO BATCH HERE\n",
    "\n",
    "    if i % 100 == 0:\n",
    "        print(f'{i}: {loss.item()}')\n",
    "    #print(loss.item())\n",
    "    \n",
    "    # backward pass\n",
    "    for p in parameters:\n",
    "        p.grad = None\n",
    "    loss.backward()\n",
    "    \n",
    "    # update\n",
    "    lr = 0.01\n",
    "    for p in parameters:\n",
    "        p.data += -lr * p.grad\n",
    "        \n",
    "    # track stats\n",
    "    #lri.append(lre[i])\n",
    "    #stepi.append(i)\n",
    "    #lossi.append(loss.log10().item())\n",
    "\n",
    "\n",
    "#print(loss.item())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 437,
   "id": "33744457-c0f3-4ea3-978b-5c747014ea33",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(2.3066, grad_fn=<NllLossBackward0>)"
      ]
     },
     "execution_count": 437,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "emb = C[Xdev]    \n",
    "h = torch.tanh(emb.view(-1, 40) @ W1 + b1) # (32, 100)\n",
    "logits = h @ W2 + b2 # (32, 27)\n",
    "loss = F.cross_entropy(logits, Ydev)\n",
    "loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 438,
   "id": "89e576f6-6195-4aac-a258-f889f441f586",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mriaalmya.\n",
      "zieel.\n",
      "ndhayah.\n",
      "rethan.\n",
      "ejdrar.\n",
      "cadered.\n",
      "eliileli.\n",
      "jellene.\n",
      "sosoraa.\n",
      "selten.\n",
      "hokea.\n",
      "noshdber.\n",
      "shimies.\n",
      "kinir.\n",
      "jelilan.\n",
      "pucriu.\n",
      "zeyvde.\n",
      "kyleli.\n",
      "ehsylae.\n",
      "myskeyd.\n",
      "ahilina.\n",
      "yansuf.\n",
      "zalel.\n",
      "juren.\n",
      "cutris.\n",
      "jaoen.\n",
      "pordin.\n",
      "kykoe.\n",
      "bhigpein.\n",
      "samuey.\n",
      "chhmreo.\n",
      "miilani.\n",
      "jevondwal.\n",
      "ayleta.\n",
      "shithne.\n",
      "sila.\n",
      "alityn.\n",
      "dabisin.\n",
      "dameel.\n",
      "ketanna.\n",
      "saavin.\n",
      "damacienna.\n",
      "alin.\n",
      "audtii.\n",
      "bryah.\n",
      "vorle.\n",
      "ajalera.\n",
      "moialo.\n",
      "litamii.\n",
      "karlon.\n"
     ]
    }
   ],
   "source": [
    "g = torch.Generator().manual_seed(2 ** 31 - 1 + 10)\n",
    "\n",
    "for _ in range(50):\n",
    "    \n",
    "    out = []\n",
    "    context = [0] * block_size\n",
    "    while True:\n",
    "        emb = C[torch.tensor([context])]\n",
    "        h = torch.tanh(emb.view(1, -1) @ W1 + b1)\n",
    "        logits = h @ W2 + b2\n",
    "        probs = F.softmax(logits, dim=1)\n",
    "        ix = torch.multinomial(probs, num_samples=1, generator=g).item()\n",
    "        context = context[1:] + [ix]\n",
    "        out.append(ix)\n",
    "        if ix == 0:\n",
    "            break\n",
    "\n",
    "    print(''.join(itos[i] for i in out))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b90d6e7-5505-43d2-a1cf-c719478f2d69",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ----------------------------------------------------------------\n",
    "# iter 10 -- fat hidden layer\n",
    "# ----------------------------------------------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 439,
   "id": "b150c1a4-1057-44d3-8490-cd5c7bc9e437",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([182544, 3]) torch.Size([182544])\n",
      "torch.Size([22740, 3]) torch.Size([22740])\n",
      "torch.Size([22862, 3]) torch.Size([22862])\n"
     ]
    }
   ],
   "source": [
    "block_size = 3 # context length: how many characters do we take to predict the next one?\n",
    "               # original paper uses a cotext of 3 words\n",
    "\n",
    "def build_dataset(words):\n",
    "    X, Y = [], []\n",
    "    for w in words:\n",
    "        context = [0] * block_size\n",
    "        for ch in w + '.':\n",
    "            ix = stoi[ch]\n",
    "            X.append(context)\n",
    "            Y.append(ix)\n",
    "            context = context[1:] + [ix] # crop first character and append, rolling window\n",
    "\n",
    "    X = torch.tensor(X)\n",
    "    Y = torch.tensor(Y)\n",
    "    print(X.shape, Y.shape)\n",
    "    return X, Y\n",
    "\n",
    "import random\n",
    "random.seed(42)\n",
    "random.shuffle(words)\n",
    "n1 = int(0.8*len(words))\n",
    "n2 = int(0.9*len(words))\n",
    "\n",
    "Xtr, Ytr = build_dataset(words[:n1])\n",
    "Xdev, Ydev = build_dataset(words[n1:n2])\n",
    "Xte, Yte = build_dataset(words[n2:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 440,
   "id": "fde11ea5-3f03-4038-a028-f73d2e9508af",
   "metadata": {},
   "outputs": [],
   "source": [
    "g = torch.Generator().manual_seed(2 ** 31 - 1) # for reproducibility\n",
    "C = torch.randn((27, 4), generator=g)\n",
    "# hidden layer\n",
    "W1 = torch.randn((12, 500), generator=g) # weights\n",
    "b1 = torch.randn(500, generator=g) # biases\n",
    "# output layer (right?)\n",
    "W2 = torch.randn((500, 27), generator=g)\n",
    "b2 = torch.randn(27, generator=g)\n",
    "parameters = [C, W1, b1, W2, b2]\n",
    "\n",
    "for p in parameters:\n",
    "    p.requires_grad = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 441,
   "id": "d52b84cd-c87d-4561-8cad-8d9c715dc399",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "20135"
      ]
     },
     "execution_count": 441,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum(p.nelement() for p in parameters) # number of parameters in total"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0bd01e45-4323-4fbd-a9dc-6f7a23db645f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0: 2.400026798248291\n",
      "1000: 2.516403913497925\n",
      "2000: 2.4230902194976807\n",
      "3000: 2.5435056686401367\n",
      "4000: 2.444976329803467\n",
      "5000: 2.3983139991760254\n",
      "6000: 2.4675819873809814\n",
      "7000: 2.6710329055786133\n",
      "8000: 2.5114474296569824\n",
      "9000: 2.3859541416168213\n",
      "10000: 2.4838268756866455\n",
      "11000: 2.405278205871582\n",
      "12000: 2.4701006412506104\n",
      "13000: 2.357053518295288\n",
      "14000: 2.462113857269287\n",
      "15000: 2.3935656547546387\n",
      "16000: 2.3927245140075684\n",
      "17000: 2.0862677097320557\n",
      "18000: 2.405197858810425\n",
      "19000: 2.271212100982666\n",
      "20000: 2.304227113723755\n",
      "21000: 2.3869893550872803\n",
      "22000: 2.2916066646575928\n",
      "23000: 2.3300557136535645\n",
      "24000: 2.214477777481079\n",
      "25000: 2.469085216522217\n",
      "26000: 2.3047218322753906\n",
      "27000: 2.4863810539245605\n",
      "28000: 2.2919373512268066\n",
      "29000: 2.328839063644409\n",
      "30000: 2.399650812149048\n",
      "31000: 2.2756433486938477\n",
      "32000: 2.3534815311431885\n",
      "33000: 2.1997742652893066\n",
      "34000: 2.411691188812256\n",
      "35000: 2.489468812942505\n",
      "36000: 2.2106142044067383\n",
      "37000: 2.440631151199341\n",
      "38000: 2.2793445587158203\n",
      "39000: 2.172184467315674\n",
      "40000: 2.1857521533966064\n",
      "41000: 2.5087921619415283\n",
      "42000: 2.430079460144043\n",
      "43000: 2.3045313358306885\n",
      "44000: 2.517206907272339\n",
      "45000: 2.6367852687835693\n",
      "46000: 2.3732800483703613\n",
      "47000: 2.329237461090088\n",
      "48000: 2.3509464263916016\n"
     ]
    }
   ],
   "source": [
    "for i in range(100000):   \n",
    "    \n",
    "    #minibatch\n",
    "    ix = torch.randint(0, Xtr.shape[0], (100,))\n",
    "\n",
    "    # forward pass    \n",
    "    emb = C[Xtr[ix]]\n",
    "    \n",
    "    h = torch.tanh(emb.view(-1, 12) @ W1 + b1) # (32, 100)\n",
    "    logits = h @ W2 + b2 # (32, 27)\n",
    "    loss = F.cross_entropy(logits, Ytr[ix]) # ALSO INDEXING INTO BATCH HERE\n",
    "\n",
    "    if i % 1000 == 0:\n",
    "        print(f'{i}: {loss.item()}')\n",
    "    #print(loss.item())\n",
    "    \n",
    "    # backward pass\n",
    "    for p in parameters:\n",
    "        p.grad = None\n",
    "    loss.backward()\n",
    "    \n",
    "    # update\n",
    "    lr = 0.01\n",
    "    for p in parameters:\n",
    "        p.data += -lr * p.grad\n",
    "        \n",
    "    # track stats\n",
    "    #lri.append(lre[i])\n",
    "    #stepi.append(i)\n",
    "    #lossi.append(loss.log10().item())\n",
    "\n",
    "\n",
    "#print(loss.item())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb551bfd-090f-4a5e-a12f-3cb5df95deb8",
   "metadata": {},
   "outputs": [],
   "source": [
    "emb = C[Xdev]    \n",
    "h = torch.tanh(emb.view(-1, 12) @ W1 + b1) # (32, 100)\n",
    "logits = h @ W2 + b2 # (32, 27)\n",
    "loss = F.cross_entropy(logits, Ydev)\n",
    "loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b11a14ea-2919-41d3-913b-7b12db913db7",
   "metadata": {},
   "outputs": [],
   "source": [
    "g = torch.Generator().manual_seed(2 ** 31 - 1 + 10)\n",
    "\n",
    "for _ in range(50):\n",
    "    \n",
    "    out = []\n",
    "    context = [0] * block_size\n",
    "    while True:\n",
    "        emb = C[torch.tensor([context])]\n",
    "        h = torch.tanh(emb.view(1, -1) @ W1 + b1)\n",
    "        logits = h @ W2 + b2\n",
    "        probs = F.softmax(logits, dim=1)\n",
    "        ix = torch.multinomial(probs, num_samples=1, generator=g).item()\n",
    "        context = context[1:] + [ix]\n",
    "        out.append(ix)\n",
    "        if ix == 0:\n",
    "            break\n",
    "\n",
    "    print(''.join(itos[i] for i in out))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d007cd5-9ad9-4169-96af-a07626e71c6b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
